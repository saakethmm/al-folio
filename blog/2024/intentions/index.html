<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  Saaketh M. Medepalli


  | Me and My Research

</title>
<meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://combinatronics.io/jwarby/pygments-css/master/github.css" />

<!-- Styles -->

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="shortcut icon" type="image/png" href="/favicon.png">
<link rel="canonical" href="/blog/2024/intentions/">


<!-- Dark Mode -->
<script src="/assets/js/theme.js"></script>
<script src="/assets/js/dark_mode.js"></script>



    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


    <script src="/assets/js/distillpub/template.v2.js"></script>
    <script src="/assets/js/distillpub/transforms.v2.js"></script>
    <script src="/assets/js/distillpub/overrides.js"></script>
    
  </head>

  <d-front-matter>
    <script async type="text/json">{
      "title": "Me and My Research",
      "description": "Why am I doing what I'm doing?",
      "published": "August 18, 2024",
      "authors": [
        
        {
          "author": "Saaketh Medepalli",
          "authorURL": "",
          "affiliations": [
            {
              "name": "Machine Learning Department, Carnegie Mellon University",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script>
  </d-front-matter>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <a class="navbar-brand title font-weight-lighter" href="https://saakethmm.github.io//">
       <span class="font-weight-bold">Saaketh</span> M.  Medepalli
      </a>
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item ">
            <a class="nav-link" href="/">
              about
              
            </a>
          </li>
          
          <!-- Blog -->
          <li class="nav-item ">
            <a class="nav-link" href="/blog/">
              blog
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                publications
                
              </a>
          </li>
          
          
          
          
          
          
          
          
            <div class="toggle-container">
              <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
    <!-- <li class="nav-item"><a class="nav-link" href="/assets/pdf/Medepalli_Saaketh_CV.pdf" target="_blank">CV</a></li> -->
  </nav>

</header>


    <!-- Content -->

    <div class="post distill">

      <d-title>
        <h1>Me and My Research</h1>
        <p>Why am I doing what I'm doing?</p>
      </d-title>

      <d-byline></d-byline>

      <d-article>
        <p>Inspired by Richard Hamming’s famous talk, <a href="http://www.cs.virginia.edu/~robins/YouAndYourResearch.html" target="_blank" rel="noopener noreferrer">“You and Your Research”</a>, I’ve been thinking about what the most important questions to ask are.</p>

<p>The way he phrases the question is also quite interesting, in the sense that it’s not just what is generally thought to be the most lucrative problems to solve (which might include things like time machines, a unified theory of physics, teleportation, telepathy (though some progress has been made here! <d-cite key="tang2022semantic"></d-cite>) or the mind-body problem/hard problem of consciousness).</p>

<p>Instead (from my interpretation) the best questions one can ask are subjective to the individual, specifically those where the individual has a good angle of attack to answer the question. In other words, one person’s most important questions might not match another’s (which has the broader implication that blindly following someone else’s research because they are passionate about it doesn’t mean you will be too - everyone needs to think carefully about their own skillsets and inclinations!).</p>

<h2 id="so-what-are-my-intentions">So, what are my intentions?</h2>

<p>With this in mind, I want to lay out some of my core interests and some specific questions I’m currently investigating and hope to investigate in the future. At the core, I think it’s important to have a clear idea of what I want to do and why I want to do it.</p>

<p>Since the summer after my freshman year of college, I’ve been very fascinated by the fields of neuroscience and AI, along with their intersection.</p>

<p><em>Why?</em> Mainly two reasons:</p>

<ol>
  <li>
    <p>The human brain is one of the most complex pieces of matter created by nature and it is one of science’s great mysteries as to how it enables such complex behavior. In addition:</p>

    <ul>
      <li>
        <p>Understanding how it enables different behaviors can allow us to treat mental afflictions such as addiction, depression &amp; anxiety and also enhance the human mind.</p>
      </li>
      <li>
        <p>It will help us more deeply understand <em>universal truths</em> through ties to several other fields (physics, philosophy, etc.).</p>
      </li>
      <li>
        <p><del>Perhaps naïvely, I optimistically believe that revealing some of the brain/mind’s mysteries will have an extensive social impact as well, just by virtue of understanding ourselves further.</del></p>
      </li>
    </ul>
  </li>
  <li>
    <p>AI (more specifically deep learning) is undisputedly the most disruptive tool right now with the rise of big data/compute. It has the potential to make tremendous impact on society (and already has in some ways <d-footnote> I promise I didn't use ChatGPT to write this, though it was tempting</d-footnote>).</p>

    <ul>
      <li>With the advent of LLMs (Large Language Models) such as GPT-4, Claude-3.5, etc., we now have the best models of intelligence so far seen in human history. It’s nice to think these models are just doing next-word prediction, but the representations learned go far, far deeper than what this simple task might give away.</li>
    </ul>
  </li>
</ol>

<p>Despite both fields somewhat diverging in their approaches (with AI especially becoming more engineering/product-driven), there are some <strong>real</strong> excitements coming at their intersection or <em>alignment</em> <d-footnote> In my view, the intersection between Cognitive Neuroscience and AI is where the level of comparison makes sense at this point (i.e., algorithmic level) in time (given deep learning really isn't biologically accurate, e.g., credit assignment problem <d-cite key="richards2019dendritic"></d-cite>) </d-footnote>, some already mainstream while others just some opinions I have <d-footnote> To be clear, others have commented on these also, though these seem to be less mainstream </d-footnote>.</p>

<h3 id="neuroscience-rightarrow-ai">Neuroscience $\rightarrow$ AI</h3>

<h4 id="popular-takes"><em>Popular Takes</em></h4>

<ul>
  <li>
    <p>Historical influence in building model architectures (e.g., Perceptron, Neocognitron, CNN, Attention mechanism <d-footnote>at least at a high level, if we define it as a flexible mechanism for controlling limited computational resources <d-cite key="lindsay2021attention"></d-cite> </d-footnote>) and potential for future contributions.</p>
  </li>
  <li>
    <p>The “AGI” Standard to which intelligence of models is held. Human brain is the demarcating line between low-level and super intelligence.</p>
  </li>
</ul>

<h4 id="my-predictions"><em>My Predictions</em></h4>

<ul>
  <li>The purpose of these models is for augmenting human capabilities (though inevitably replacing for more mundane tasks), so learning interactions with these models will be of tremendous value. Understanding our own minds is still a necessary endeavor that will be vital for future AI-human interactions and BMI (brain-machine interfaces <d-footnote> Not to be confused with body-mass index </d-footnote>).</li>
</ul>

<h3 id="ai-rightarrow-neuroscience">AI $\rightarrow$ Neuroscience</h3>

<h4 id="popular-takes-1"><em>Popular Takes</em></h4>

<ul>
  <li>
    <p>Language and vision models based on deep learning (e.g., Transformers for language, CNNs for vision) have proved to be the best models so far successful in predicting held-out brain activity <d-cite key="antonello2024scalinglawslanguageencoding"></d-cite> <d-cite key="margalit2024unifying"></d-cite>.</p>
  </li>
  <li>
    <p>By optimizing solutions for certain tasks across domains (e.g., object inpainting (CV), next-word prediction (NLP), robot stepping up a stair (robotics), etc.), representations to address those tasks will continue to improve and perhaps converge onto the brain <d-cite key="hermann2023human"></d-cite>.</p>
  </li>
</ul>

<h4 id="my-predictions-1"><em>My Predictions</em></h4>

<ul>
  <li>
    <p>Though we’ve been treating neural networks as black boxes since their widespread adoption in 2012, recent work in interpretability has shattered this notion <d-cite key="templeton2024scaling"></d-cite> <d-cite key="marks2024sparsefeaturecircuitsdiscovering"></d-cite>. Despite it being a work in progress, there are now clearer ways to reveal the role of circuits within the larger network.</p>

    <ul>
      <li>
        <p>Combined with the first popular take above, this means we can intervene on the circuits in the neural networks to elicit some behavioral change, upon which we can observe the causal effect of this intervention on the brain predictivity <d-cite key="lindsay2023groundingneurosciencebehavioralchanges"></d-cite>.</p>
      </li>
      <li>
        <p>With enough brain data, we can directly train/fine-tune models to predict brain activity and peer into the resulting <em>in silico</em> models using these methods. This line of work has already shown very cool results <d-cite key="khosla2022high"></d-cite> <d-cite key="luo2023braindiffusionvisualexploration"></d-cite> and will prove to be very promising.</p>
      </li>
    </ul>
  </li>
</ul>

<h3 id="ai-leftrightarrow-neuroscience">AI $\leftrightarrow$ Neuroscience?</h3>

<p>But the story doesn’t end there folks. There’s a rising notion that apart from the higher-level behaviors that seem to be converging (evidenced by consistent improvement on the latest benchmarks), the representations learned by artificial and biological neural networks are <em>also</em> converging <d-cite key="huh2024platonicrepresentationhypothesis"></d-cite>. In other words, we’re seeing <em>representational alignment</em> <d-footnote> A natural question to ask is what exactly what we are aligning to. This paper argues that there is an underlying, objective reality, akin to Plato's Theory of Forms, that all intelligent systems learn some form of</d-footnote>.</p>

<p>In my view, this idea, if shown to be valid, could have profound implications for a number of fields across science, not just cognitive science/neuroscience/AI. One example has already been briefly mentioned - representing the brain via <em>in silico</em> models, upon which we can do extensive analysis since every attribute of the model (now brain) is fully accessible and modifiable.  <d-footnote> Note: The focus so far has been on Marr's 1st and 2nd levels, but we havent't discussed the 3rd. Folks are working on alignment here as well (e.g., neuromorphic engineering) but representational alignment is somewhat independent of the mechanism by which the algorithms are implemented, since things like weight sharing or pooling may not exist within neuronal circuits in the brain </d-footnote>.</p>

<p>Another fuzzy and highly speculative possibility is that if this convergence is accurate, there might be a <a href="https://www.psychologytoday.com/us/blog/the-digital-self/202405/ais-quest-for-a-grand-unification-theory" target="_blank" rel="noopener noreferrer">unification with ideas from quantum mechanics</a>, which currently has to deal with the <a href="https://en.wikipedia.org/wiki/Observer_effect_(physics)#Quantum_mechanics" target="_blank" rel="noopener noreferrer">observer effect</a>. To be more specific, if the hypothesis turns out to be accurate, maybe we could use <em>in silico</em> models to represent the <strong>first-person experience</strong> of a quantum mechanical process <d-footnote></d-footnote></p>

<!-- I explore the potential impact *in silico* modeling will have on science here  -->

<h2 id="what-are-my-important-problems">What are my important problems?</h2>

<p>As a whole, I find that my core interests lean towards this broad question of AI-human alignment at the representational level, but also at the behavioral/value level.</p>

<p>I’ve explored the former question thoroughly in this blog post, which is what I’m currently working on, in the domain of language. The question is notoriously complex when broken down: how do vibrations entering our ears get translated into a coherent group of sounds that we interpret as language? To make matters more confusing, this language takes place in our mind as thoughts, but how does this even happen (i.e., mind-body problem)? Due to the rapid advancements in language models along with interpretability research, it is an interesting time to be studying how LLMs process language and how that compares to the mechanisms by which the brain processes language. Discovering some shared principles could be fruitful to neuroscience research along with building more human-aligned, interpretable AI systems.</p>

<p>Another question (on a rather different, but related, note) that is very dear to me is how to build AI systems that are aligned with our goals of constructing meaningful, happy lives, akin to what folks over at the <a href="https://www.meaningalignment.org/" target="_blank" rel="noopener noreferrer">Meaning Alignment Institute</a> are working on. This is definitely a topic for another post, but to keep it short, many people in my generation (Gen Z) are suffering. From anxiety and depression to comparisons and short-attention spans, high-speed access to very potent stimuli (e.g., social media, video games, pornography, YouTube, etc.) has allowed mental health issues to skyrocket at unprecedented rates. AI has the potential to profoundly exacerbate these problems or improve people’s lives. The other important problem for me in the future is to help construct AI models/frameworks/applications that can steer people’s lives in a positive direction.</p>

<h2 id="future-of-blog">Future of Blog</h2>

<p>I see two roles for this blog:</p>
<h3 id="1-exploring-fun-scientific-topics">1. Exploring Fun Scientific Topics</h3>

<p>I think this is an exciting time to be in the field of representational alignment, and I’m looking forward to what’s to come. I hope to write about topics related to this area (or beyond) that I find interesting, across topics in machine learning, AI alignment, neuroscience, philosophy and more. I’d like to also use this as an avenue to learn about cool and relevant new ideas/papers (see list below), and experiment with ways to distill these into useful explanations.</p>

<p>Here’s a list of topics that I’m interested in diving deeper into:</p>

<ul>
  <li>Foundation Models <!-- Past-transformers (Can we improve them to be more useful?), Flash Attention, MoE to gating information? Similarly, JEPA for vision, other RL models, KAN -->
</li>
  <li>Representation Learning  <!-- What features are learned? During training, what is really going on? (grokking paper, mechanistic analysis of training process) -->
</li>
  <li>Interpreting Representations <!-- Interpretability techniques -->
</li>
  <li>Editing Representations <!-- Model Editing -->
</li>
  <li>Alignment Metrics  <!-- Predictivity (regression), RSA, etc.  -->
</li>
  <li>Improving Alignment <!-- Better tasks (Aran's work), Flash Attention, etc. -->
</li>
  <li>Human-AI Alignment <!-- RLHF, Meaning alignment (moral graphs) -->
</li>
  <li>… and more!</li>
</ul>

<h3 id="2-random-other-topics">2. Random Other Topics</h3>

<p>I tend to go down rabbit holes quite often when something strikes me as curious, so I’ll use the blog also as an avenue to explore miscellaneous topics that I find interesting in the moment and perhaps want to elucidate more for myself. Some topics of interest are philosophy (Western &amp; Eastern), geopolitics, Indian history/culture, future of technology/AI, health, etc.</p>

<h3 id="the-end-is-just-the-beginning">The End is Just the Beginning</h3>

<p>Due to other obligations, the posting schedule will be pretty random since I’m just getting into the hang of it, though hopefully I’ll find a more regular schedule in the future. Stay tuned! <!-- re-aligned on Representational alignment (How special are these representations?) Platonic Rep Hypothesis --></p>

<p><em>Last modified on 11/4/2024</em></p>

      </d-article>

      <d-appendix>
        <d-footnote-list></d-footnote-list>
        <d-citation-list></d-citation-list>
      </d-appendix>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    © Copyright 2024 Saaketh M. Medepalli.
    Powered by <a href="http://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="noopener noreferrer">Unsplash</a>.

    
    
  </div>
</footer>



  </body>

  <d-bibliography src="/assets/bibliography/2024-06-23-intentions.bib">
  </d-bibliography>

</html>
