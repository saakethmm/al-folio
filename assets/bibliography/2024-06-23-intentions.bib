
@article{tang2022semantic,
	abstract = {A brain-computer interface that decodes continuous language from non-invasive recordings would have many scientific and practical applications. Currently, however, decoders that reconstruct continuous language use invasive recordings from surgically implanted electrodes1{\textendash}3, while decoders that use non-invasive recordings can only identify stimuli from among a small set of letters, words, or phrases4{\textendash}7. Here we introduce a non-invasive decoder that reconstructs continuous natural language from cortical representations of semantic meaning8 recorded using functional magnetic resonance imaging (fMRI). Given novel brain recordings, this decoder generates intelligible word sequences that recover the meaning of perceived speech, imagined speech, and even silent videos, demonstrating that a single language decoder can be applied to a range of semantic tasks. To study how language is represented across the brain, we tested the decoder on different cortical networks, and found that natural language can be separately decoded from multiple cortical networks in each hemisphere. As brain-computer interfaces should respect mental privacy9, we tested whether successful decoding requires subject cooperation, and found that subject cooperation is required both to train and to apply the decoder. Our study demonstrates that continuous language can be decoded from non-invasive brain recordings, enabling future multipurpose brain-computer interfaces.},
	author = {Tang, Jerry and LeBel, Amanda and Jain, Shailee and Huth, Alexander G.},
	doi = {10.1101/2022.09.29.509744},
	elocation-id = {2022.09.29.509744},
	eprint = {https://www.biorxiv.org/content/early/2022/09/29/2022.09.29.509744.full.pdf},
	journal = {bioRxiv},
	publisher = {Cold Spring Harbor Laboratory},
	title = {Semantic reconstruction of continuous language from non-invasive brain recordings},
	url = {https://www.biorxiv.org/content/early/2022/09/29/2022.09.29.509744},
	year = {2022},
	Bdsk-Url-1 = {https://www.biorxiv.org/content/early/2022/09/29/2022.09.29.509744},
	Bdsk-Url-2 = {https://doi.org/10.1101/2022.09.29.509744}
}

@misc{antonello2024scalinglawslanguageencoding,
      title={Scaling laws for language encoding models in fMRI}, 
      author={Richard Antonello and Aditya Vaidya and Alexander G. Huth},
      year={2024},
      eprint={2305.11863},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2305.11863}, 
}

@article{margalit2024unifying,
	abstract = {A key feature of many cortical systems is functional organization: the arrangement of neurons with specific functional properties in characteristic spatial patterns across the cortical surface. However, the principles underlying the emergence and utility of functional organization are poorly understood. Here we develop the Topographic Deep Artificial Neural Network (TDANN), the first unified model to accurately predict the functional organization of multiple cortical areas in the primate visual system. We analyze the key factors responsible for the TDANN{\textquoteright}s success and find that it strikes a balance between two specific objectives: achieving a task-general sensory representation that is self-supervised, and maximizing the smoothness of responses across the cortical sheet according to a metric that scales relative to cortical surface area. In turn, the representations learned by the TDANN are lower dimensional and more brain-like than those in models that lack a spatial smoothness constraint. Finally, we provide evidence that the TDANN{\textquoteright}s functional organization balances performance with inter-area connection length, and use the resulting models for a proof-of-principle optimization of cortical prosthetic design. Our results thus offer a unified principle for understanding functional organization and a novel view of the functional role of the visual system in particular.Competing Interest StatementThe authors have declared no competing interest.},
	author = {Margalit, Eshed and Lee, Hyodong and Finzi, Dawn and DiCarlo, James J. and Grill-Spector, Kalanit and Yamins, Daniel L. K.},
	doi = {10.1101/2023.05.18.541361},
	elocation-id = {2023.05.18.541361},
	eprint = {https://www.biorxiv.org/content/early/2023/05/18/2023.05.18.541361.full.pdf},
	journal = {bioRxiv},
	publisher = {Cold Spring Harbor Laboratory},
	title = {A Unifying Principle for the Functional Organization of Visual Cortex},
	url = {https://www.biorxiv.org/content/early/2023/05/18/2023.05.18.541361},
	year = {2023},
	Bdsk-Url-1 = {https://www.biorxiv.org/content/early/2023/05/18/2023.05.18.541361},
	Bdsk-Url-2 = {https://doi.org/10.1101/2023.05.18.541361}
}

@article{hermann2023human,
  title={For human-like models, train on human-like tasks},
  author={Hermann, Katherine and Nayebi, Aran and van Steenkiste, Sjoerd and Jones, Matthew},
  year={2023},
  publisher={PsyArXiv},
  doi={https://osf.io/preprints/psyarxiv/a35mt}
}

@misc{hermann2023human,
 title={For Human-Like Models, Train on Human-Like Tasks},
 url={osf.io/preprints/psyarxiv/a35mt},
 DOI={10.31234/osf.io/a35mt},
 publisher={PsyArXiv},
 author={Hermann, Katherine and Nayebi, Aran and van Steenkiste, Sjoerd and Jones, Matthew},
 year={2023},
 month={Mar}
}

@article{richards2019dendritic,
	abstract = {Guaranteeing that synaptic plasticity leads to effective learning requires a means for assigning credit to each neuron for its contribution to behavior. The `credit assignment problem' refers to the fact that credit assignment is non-trivial in hierarchical networks with multiple stages of processing. One difficulty is that if credit signals are integrated with other inputs, then it is hard for synaptic plasticity rules to distinguish credit-related activity from non-credit-related activity. A potential solution is to use the spatial layout and non-linear properties of dendrites to distinguish credit signals from other inputs. In cortical pyramidal neurons, evidence hints that top-down feedback signals are integrated in the distal apical dendrites and have a distinct impact on spike-firing and synaptic plasticity. This suggests that the distal apical dendrites of pyramidal neurons help the brain to solve the credit assignment problem.},
	author = {Blake A Richards and Timothy P Lillicrap},
	doi = {https://doi.org/10.1016/j.conb.2018.08.003},
	issn = {0959-4388},
	journal = {Current Opinion in Neurobiology},
	note = {Neurobiology of Learning and Plasticity},
	pages = {28-36},
	title = {Dendritic solutions to the credit assignment problem},
	url = {https://www.sciencedirect.com/science/article/pii/S0959438818300485},
	volume = {54},
	year = {2019},
	Bdsk-Url-1 = {https://www.sciencedirect.com/science/article/pii/S0959438818300485},
	Bdsk-Url-2 = {https://doi.org/10.1016/j.conb.2018.08.003}
}

@article{templeton2024scaling,
       title={Scaling Monosemanticity: Extracting Interpretable Features from Claude 3 Sonnet},
       author={Templeton, Adly and Conerly, Tom and Marcus, Jonathan and Lindsey, Jack and Bricken, Trenton and Chen, Brian and Pearce, Adam and Citro, Craig and Ameisen, Emmanuel and Jones, Andy and Cunningham, Hoagy and Turner, Nicholas L and McDougall, Callum and MacDiarmid, Monte and Freeman, C. Daniel and Sumers, Theodore R. and Rees, Edward and Batson, Joshua and Jermyn, Adam and Carter, Shan and Olah, Chris and Henighan, Tom},
       year={2024},
       journal={Transformer Circuits Thread},
       url={https://transformer-circuits.pub/2024/scaling-monosemanticity/index.html}
}

@misc{marks2024sparsefeaturecircuitsdiscovering,
      title={Sparse Feature Circuits: Discovering and Editing Interpretable Causal Graphs in Language Models}, 
      author={Samuel Marks and Can Rager and Eric J. Michaud and Yonatan Belinkov and David Bau and Aaron Mueller},
      year={2024},
      eprint={2403.19647},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2403.19647}, 
}

@article{khosla2022high,
	abstract = {Investigation of the visual system has mainly relied on a-priori hypotheses to restrict experimental stimuli or models used to analyze experimental data. Hypotheses are an essential part of scientific inquiry, but an exclusively hypothesis-driven approach might lead to confirmation bias towards existing theories and away from novel discoveries not predicted by them. This paper uses a hypothesis-neutral computational approach to study four high-level visual regions of interest (ROIs) selective to faces, places, letters, or body parts. We leverage the unprecedented scale and quality of the Natural Scenes Dataset to constrain neural network models of these ROIs with functional Magnetic Resonance Imaging (fMRI) measurements. We show that using only the stimulus images and the associated activity in an ROI, we are able to train from scratch a neural network that can predict the activity in each voxel of that ROI with an accuracy that beats state-of-the-art models. Moreover, once trained, the ROI-specific networks can reveal what kinds of functional properties emerge spontaneously in their training. Strikingly, despite no category-level supervision, the units in the trained networks act strongly as detectors for semantic concepts like {\textquoteleft}faces{\textquoteright} or {\textquoteleft}words{\textquoteright}, thereby providing sub-stantial pieces of evidence for categorical selectivity in these visual areas. Importantly, this selectivity is maintained when training the networks with selective deprivations in the training diet, by excluding images that contain their preferred category. The resulting selectivity in the trained networks strongly suggests that the visual areas do not function as exclusive category detectors but are also sensitive to visual patterns that are typical to their preferred categories, even in the absence of these categories. Finally, we show that our response-optimized networks have distinct functional properties. Together, our findings suggest that response-optimized models combined with model interpretability techniques can serve as a powerful and unifying computational framework for probing the nature of representations and computations in the brain.Competing Interest StatementThe authors have declared no competing interest.},
	author = {Khosla, Meenakshi and Wehbe, Leila},
	doi = {10.1101/2022.03.16.484578},
	elocation-id = {2022.03.16.484578},
	eprint = {https://www.biorxiv.org/content/early/2022/03/18/2022.03.16.484578.full.pdf},
	journal = {bioRxiv},
	publisher = {Cold Spring Harbor Laboratory},
	title = {High-level visual areas act like domain-general filters with strong selectivity and functional specialization},
	url = {https://www.biorxiv.org/content/early/2022/03/18/2022.03.16.484578},
	year = {2022},
	Bdsk-Url-1 = {https://www.biorxiv.org/content/early/2022/03/18/2022.03.16.484578},
	Bdsk-Url-2 = {https://doi.org/10.1101/2022.03.16.484578}
}


@misc{luo2023braindiffusionvisualexploration,
      title={Brain Diffusion for Visual Exploration: Cortical Discovery using Large Scale Generative Models}, 
      author={Andrew F. Luo and Margaret M. Henderson and Leila Wehbe and Michael J. Tarr},
      year={2023},
      eprint={2306.03089},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2306.03089}, 
}

@misc{huh2024platonicrepresentationhypothesis,
      title={The Platonic Representation Hypothesis}, 
      author={Minyoung Huh and Brian Cheung and Tongzhou Wang and Phillip Isola},
      year={2024},
      eprint={2405.07987},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2405.07987}, 
}

@article{khosla2024privileged,
	abstract = {How do neurons code information? Recent work emphasizes properties of population codes, such as their geometry and decodable information, using measures that are blind to the native tunings (or {\textquoteleft}axes{\textquoteright}) of neural responses. But might these representational axes matter, with some privileged systematically over others? To find out, we developed methods to test for alignment of neural tuning across brains and deep convolutional neural networks (DCNNs). Across both vision and audition, both brains and DCNNs consistently favored certain axes for representing the natural world. Moreover, the representational axes of DCNNs trained on natural inputs were aligned to those in perceptual cortices, such that axis-sensitive model-brain similarity metrics better differentiated competing models of biological sensory systems. We further show that coding schemes that privilege certain axes can reduce downstream wiring costs and improve generalization. These results motivate a new framework for understanding neural tuning in biological and artificial networks and its computational benefits.Competing Interest StatementThe authors have declared no competing interest.},
	author = {Khosla, Meenakshi and Williams, Alex H and McDermott, Josh and Kanwisher, Nancy},
	doi = {10.1101/2024.06.20.599957},
	elocation-id = {2024.06.20.599957},
	eprint = {https://www.biorxiv.org/content/early/2024/06/20/2024.06.20.599957.full.pdf},
	journal = {bioRxiv},
	publisher = {Cold Spring Harbor Laboratory},
	title = {Privileged representational axes in biological and artificial neural networks},
	url = {https://www.biorxiv.org/content/early/2024/06/20/2024.06.20.599957},
	year = {2024},
	Bdsk-Url-1 = {https://www.biorxiv.org/content/early/2024/06/20/2024.06.20.599957},
	Bdsk-Url-2 = {https://doi.org/10.1101/2024.06.20.599957}}


@misc{lindsay2023groundingneurosciencebehavioralchanges,
      title={Grounding Neuroscience in Behavioral Changes using Artificial Neural Networks}, 
      author={Grace W. Lindsay},
      year={2023},
      eprint={2311.07526},
      archivePrefix={arXiv},
      primaryClass={q-bio.NC},
      url={https://arxiv.org/abs/2311.07526}, 
}

@article{lindsay2021attention,
	author = {Lindsay, Grace W.},
	doi = {10.3389/fncom.2021.698574},
	issn = {1662-5188},
	journal = {Frontiers in Computational Neuroscience},
	title = {Corrigendum: Attention in Psychology, Neuroscience, and Machine Learning},
	url = {https://www.frontiersin.org/journals/computational-neuroscience/articles/10.3389/fncom.2021.698574},
	volume = {15},
	year = {2021},
	Bdsk-Url-1 = {https://www.frontiersin.org/journals/computational-neuroscience/articles/10.3389/fncom.2021.698574},
	Bdsk-Url-2 = {https://doi.org/10.3389/fncom.2021.698574}
}


